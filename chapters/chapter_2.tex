
\chapter{相关技术及理论}
    计算机视觉定位技术将相机作为传感器获取图像，并采用目标跟踪与检测算法提取图像中的特征信息，最后利用特征信息对机器人进行位姿估计。\par
    本章分为四个部分：第一个部分描述针孔相机模型中主要坐标系之间的转换过程；第二个部分介绍相机内参标定方法，说明典型方法的具体原理和优缺点；第三个部分介绍目标跟踪与目标检测技术，描述主流方法的相关过程和特点；第四个部分对常见的位姿估计方法进行分析。
\section{坐标系转换}
    在计算机视觉中，针孔相机模型是一个常用的几何模型，它通过小孔成像的原理描述了三维世界中坐标点映射到二维图像平面的过程。针孔相机模型中的主要坐标系包括世界坐标系、相机坐标系、图像坐标系和像素坐标系。\par
    世界坐标系通常被定义为模型中的基准坐标系，以该坐标系为基础，物体在真实世界中的位置得以被数据化，在相机标定中世界坐标系通常被用于描述相机的实际位置。相机坐标系以相机的光心为坐标原点，其~xy~平面与成像平面平行，将空间中物体的位置以相机的角度进行表示。图像坐标系和像素坐标系描述了针孔相机模型中二维部分，其中图像坐标系以图像主点为坐标原点，形成的平面与成像平面重合，它描述了成像过程中物体从相机坐标系到图像坐标系的投影透视关系，而像素坐标系的坐标原点位于图像最左上角的像素点，描述了物体成像后的像素点在图像中的位置。上述坐标系的关系如图\ref{img2_1}所示，
    \begin{figure}[htb]
        \centering
        \includegraphics[width=0.6\textwidth]{2-1.pdf}
        \caption{针孔相机模型}
        \label{img2_1}
    \end{figure}
    紫色坐标系是世界坐标系~O$_w$-x-y-z~，绿色坐标系是相机坐标系~O$_c$-x-y-z~，灰色坐标系是图像坐标系~O$_i$-x-y~，蓝色坐标系是像素坐标系~O$_p$-x-y~。\par
    世界坐标系与相机坐标系之间的转换是一种刚体变换，描述了相机在三维空间中的位置以及拍摄的角度。旋转与平移作用于世界坐标系中的三维坐标点~$P_w(X_w,Y_w,Z_w)$~，将其转换为该点在相机坐标系下的坐标~$P_c(X_c,Y_c,Z_c)$~，转换过程如公式\ref{wToc}所示。
    \begin{equation}
        \begin{bmatrix}
            X_c \\
            Y_c \\
            Z_c \\
            1
        \end{bmatrix}
        =
        \begin{bmatrix}
            R & t \\
            0 & 1
        \end{bmatrix}
        \begin{bmatrix}
            X_w \\
            Y_w \\
            Z_w \\
            1
        \end{bmatrix}
        =R
        \begin{bmatrix}
            X_w \\
            Y_w \\
            Z_w 
        \end{bmatrix}
        +t
        \label{wToc}
    \end{equation}
    公式\ref{wToc}中以齐次坐标的方式进行矩阵相乘，~$R$~表示3*3旋转矩阵，~$t$~表示3*1平移矩阵。它们的组合代表了相机的外参，描述了相对于世界坐标系，相机在三维空间中的位姿信息。\par
    相机坐标系与图像坐标系之间的转换是一种投影透视的过程。相机坐标系的~xy~平面与成像平面之间的物理距离被称为焦距~f~，~z~轴垂直成像平面，穿过图像主点，而相机坐标系下的三维点~$P_c$~与坐标原点的连线与图像平面相交，形成一个投影点~$p$~，如图\ref{img2_2}所示，
    \begin{figure}[htb]
        \centering
        \includegraphics[width=0.8\textwidth]{2-2.pdf}
        \caption{3D点投影形成示意图}
        \label{img2_2}
    \end{figure}
    该投影点的坐标是三维点在图像坐标系下的坐标~$p(x,y)$~。图\ref{img2_2}中构成两组相似三角形关系，利用该关系构建等式，整理得：
    \begin{equation}
        Z_c
        \begin{bmatrix}
            x \\
            y \\
            1
        \end{bmatrix}
        =
        \begin{bmatrix}
            f & 0 & 0 \\
            0 & f & 0 \\
            0 & 0 & 1
        \end{bmatrix}
        \begin{bmatrix}
            X_c \\
            Y_c \\
            Z_c
        \end{bmatrix}
        \label{cToi2}
    \end{equation}
    这个过程涉及了相机的焦距~$f$~，将三维的坐标转化为二维，是空间信息到平面信息的转变。\par
    图像坐标系与像素坐标系之间的转换是缩放与平移的过程。图像坐标系通过物理单位描述投影点在图像中的位置，而像素坐标系则以像素数目为单位表示投影点在图像中的位置。因此，每个像素点在图像平面~x~方向上的物理尺寸~$dx$~以及~y~方向上的物理尺寸~$dy$~是实现两个坐标系转换的关键，而这两者可通过相机内参标定获取的。公式\ref{iTop2}描述了二维坐标缩放与平移的过程。
    \begin{equation}
        \begin{bmatrix}
            u \\
            v \\
            1
        \end{bmatrix}
        =
        \begin{bmatrix}
            \frac{1}{dx} & 0 & c_x \\
            0 & \frac{1}{dy} & c_y \\
            0 & 0 & 1
        \end{bmatrix}
        \begin{bmatrix}
            x \\
            y \\ 
            1
        \end{bmatrix}
        \label{iTop2}
    \end{equation}
    其中~$u$~和~$v$~表示投影点在像素坐标系下的二维坐标，而~$c_x$~和~$c_y$~表示平移部分的标量，共同构成了图像的主点坐标。这个转换过程涉及了相机的像元尺寸~$dx$~与~$dy$~以及主点坐标~$c_x$~与~$c_y$~，它们分别表示了坐标系转换中的缩放部分与平移部分，是相机内参的一部分，实现了从物理尺寸到像素数目的转换。
    \par
    结合公式\ref{wToc}、公式\ref{cToi2}和公式\ref{iTop2}，可以得到一个比较明确的转换关系，如公式\ref{wTop}所示：
    \begin{equation}
        Z_c
        \begin{bmatrix}
            u \\
            v \\
            1
        \end{bmatrix}
        =
        \begin{bmatrix}
            f_x & 0 & c_x \\
            0 & f_y & c_y \\
            0 & 0 & 1
        \end{bmatrix}
        \begin{bmatrix}
            R & t
        \end{bmatrix}
        \begin{bmatrix}
            X_w \\
            Y_w \\
            Z_w \\
            1
        \end{bmatrix}
        \label{wTop}
    \end{equation}
    其中~$f_x$~等于~$\frac{f}{dx}$，~$f_y$~等于~$\frac{f}{dy}$~。由公式\ref{wTop}可见，世界坐标系下的坐标经过相机内参矩阵$\begin{bmatrix}
        f_x & 0 & c_x \\
        0 & f_y & c_y \\
        0 & 0 & 1
    \end{bmatrix}$和相机外参矩阵$\begin{bmatrix}
        R & t
    \end{bmatrix}$的作用转化为像素坐标系下的坐标。
\section{相机内参标定方法}
    相机是计算机视觉定位中的重要传感器，针孔相机模型的构建对~3D~点的投影过程进行了清晰的解释。在针孔相机模型中涉及了一些相机本身的设备参数，如相机焦距~$f$~，相机的像元尺寸~$dx$~与~$dy$~以及成像平面的主点($c_x$,$c_y$)，这些参数也被称为相机内参，在三维坐标点投影成为二维像素点的过程中有着重要的作用。相机内参标定方法的主要目的是对这些设备参数的估计求解，参数精度影响着投影后二维像素点的位置，因此相机内参标定方法围绕对相机内参的精度优化不断发展至今。\par    
    相机标定方法根据其标定的方式分为主动视觉相机标定法、相机自标定法和传统相机标定法。主动视觉相机标定法求解内参的过程并不复杂，多次求解所得的内参结果异常值较少，此外它无需标记物辅助标定，但是成本却是三类方法中最高的，常用的方法是使用定制系统控制相机做规定的运动进行标定。相机自标定法虽然有很强的灵活性，但是其在精度和稳定性方面的表现较差，比如分层逐步标定\upcite{hartley1994projective}和基于~Kruppa~的自标定法\upcite{zeller1996}。传统相机标定法依赖于棋盘、点阵等标记物，但是其泛用性高、精度可观、使用门槛低，使用较多的方法有~Tsai~两步法\upcite{tsai1986an,tsai1987a}和张正友标定法\upcite{zhang2000a}，其中张正友标定法因其简单的辅助标定物和高精度被广泛使用。\par
    张正友标定法是一种基于平面棋盘格的标定方法，它由以下几个部分组成：\par
    （1）两个平面之间的单应性。张氏标定法中涉及两个平面：棋盘格平面和图像平面。它们之间的投影映射关系由单应矩阵~$H$~表示，即棋盘格平面上~3D~点坐标在单应矩阵的作用下转化为图像平面上的~2D~点坐标，如公式\ref{h1}所示。
    \begin{equation}
        s
        \begin{bmatrix}
            u \\
            v \\
            1
        \end{bmatrix}
        =H
        \begin{bmatrix}
            X_w \\
            Y_w \\
            Z_w \\
            1
        \end{bmatrix}
        \label{h1}
    \end{equation}
    其中~$s$~表示尺度，与公式\ref{wTop}中的~$Z_c$~意义相同。若将外参矩阵~$[R \quad t]$~按照列向量的形式写成~$[r_1 \quad r_2 \quad r_3 \quad t]$~，并使世界坐标系的~xy~平面与棋盘格标记物的平面重叠，那么对于棋盘格上的~3D~点，它们的~$Z_w$~全都为~0~，因此可将~$r_3$~这列消去，结合公式\ref{wTop}得到公式\ref{h2}：
    \begin{equation}
        s
        \begin{bmatrix}
            u \\
            v \\
            1
        \end{bmatrix}
        =K
        \begin{bmatrix}
            r_1 & r_2 & t
        \end{bmatrix}
        \begin{bmatrix}
            X_w \\
            Y_w \\
            1
        \end{bmatrix}
        \label{h2}
    \end{equation}
    于是3*3单应矩阵可表示为未知相机内参矩阵与简化相机外参矩阵的乘积，如公式\ref{H}所示。
    \begin{equation}
        H=
        \begin{bmatrix}
            h_1 & h_2 & h_3
        \end{bmatrix}
        =K
        \begin{bmatrix}
            r1 & r2 & t
        \end{bmatrix}
        \label{H}
    \end{equation}
    其中~$[h_1 \quad h_2 \quad h_3]$~是以列向量形式表示的单应矩阵。单应矩阵有~8~个未知量需要求解，利用已知的至少四对~3D~点与~2D~点的坐标可以求解出单应矩阵。
    \par
    （2）利用约束条件求解内参矩阵~$K$~。单应矩阵由内参矩阵与外参矩阵相乘得到，而内参矩阵与外参矩阵均为未知，无法正常求解。此时外参矩阵中旋转量~$R$~的约束条件成为求解内参的突破口，~$R$~是一个正交矩阵，其列向量相互正交且模均为~1~，根据约束条件将外参矩阵消去，得到如下等式：
    \begin{equation}
        \begin{aligned}
            h_1^TK^{-T}K^{-1}h_2 &= 0 \\
            h_1^TK^{-T}K^{-1}h_1 &= h_2^TK^{-T}K^{-1}h_2    
        \end{aligned}
        \label{hK}
    \end{equation}
    在内参矩阵中存在~5~个待求解的未知量，这~5~个未知量能够唯一求解的条件是至少已知三个单应矩阵。令矩阵~$B$~表示~$K^{-T}K^{-1}$~，3*3矩阵~$B$~是一个对称矩阵，原本~$B$~中的~9~个未知量减少为~6~个，于是将~$B$~写成六维向量~$b$~的形式，如公式\ref{B}所示：
    \begin{equation}
        B=
        \begin{bmatrix}
            B_{11} & B_{12} & B_{13} \\
            B_{21} & B_{22} & B_{23} \\
            B_{31} & B_{32} & B_{33} \\
        \end{bmatrix}
        \quad
        b=
        \begin{bmatrix}
            B_{11} & B_{12} & B_{22} & B_{13} & B_{23} & B_{33}
        \end{bmatrix}
        ^T
        \label{B}
    \end{equation}
    结合公式\ref{hK}得到一个简化的等式：
    \begin{equation}
        Vb=0
    \end{equation}
    式中~$V$~是一个~2n*6~的已知矩阵，与单应矩阵相关。最后将三个单应矩阵结合组成~$V$~，通过奇异值分解求解~$b$~，从而得到唯一的内参矩阵~$K$~。
    \par
    （3）标定精度优化。标定方法中常采用最小化重投影误差的方法对内参进行优化，即将空间坐标按照当前估计的外参与内参投影到像素平面，根据图像检测算法检测得到的像素点和重投影的像素点之间的像素偏差构造代价函数，通过最小化代价函数进一步优化这些估计的参数，如公式\ref{LM}所示。
    \begin{equation}
        \sum_{i=1}^n\sum_{j=1}^m||p_{ij}-\hat{p}(K,R_i,t_i,(P_w)_j)||^2
        \label{LM}
    \end{equation}
    式中~$i$~与~$j$~分别表示相机位置的编号与一个相机位置中~3D~点的编号，~$p_{ij}$~表示在第~$i$~号的相机位置上第~$j$~个~3D~点原本在图像中检测的像素位置，~$\hat{p}$~表示该~3D~点重投影后的像素位置。这个优化问题其实是一个最小二乘问题，常使用列文伯格-马夸尔特方法迭代求解。\par
    张正友标定法解决了传统标定法原本操作繁琐、标定物精度要求高的问题，同时相对自标定大大提升了标定的精度，因此成为了主流的相机内参标定方法。
\section{目标跟踪与检测技术}
    在计算机视觉定位领域，图像是唯一的视觉信息来源，目标跟踪与检测技术能够将图像中的冗余信息过滤，提取关键特征信息。本节对目标跟踪技术与目标检测技术进行介绍。
\subsection{目标跟踪技术}
    目标跟踪通常指单目标跟踪，在第一帧图像中获取输入的矩形框指定跟踪目标，并在后续的每一帧中找到目标的运动位置，如图\ref{img2_5}所示。
    \begin{figure}[htb]
        \centering
        \includegraphics[width=0.65\textwidth]{2-5.jpg}
        \caption{目标跟踪实例}
        \label{img2_5}
    \end{figure}
    定位技术借助目标跟踪方法缩小图像处理的范围，提高定位效率与精度。目标跟踪的重点在于对目标物体的动态感知，包括目标的形状、移动速度等，因此目标跟踪过程中目标的形变、运动速度过快、模糊等问题极大地影响了跟踪的效果。此外环境光照的变化、背景的干扰等环境因素降低了跟踪的精度。为应对上述问题，诸多目标跟踪方法被提出，它们从实现方式上的不同被分为生成模型方法和判别模型方法。\par
    生成模型方法能够提取图像中的目标特征并根据这些特征生成目标的外观模型，方法中把该模型当作匹配目标，在图像中搜索与其最匹配的区域，将这个区域作为跟踪结果，从而达到跟踪的目的，其运作原理如图\ref{img2_3}所示。
    \begin{figure}[htb]
        \centering
        \includegraphics[width=0.9\textwidth]{2-3.pdf}
        \caption{生成模型方法原理图}
        \label{img2_3}
    \end{figure}
    均值漂移算法\upcite{fukunaga1975the}、卡尔曼滤波算法\upcite{kalman1960a}和粒子滤波\upcite{NummiaroAn}是生成模型方法中常用的算法，主要用于对目标区域的加速匹配，围绕这些算法，~L1 Tracker~\upcite{mei2009robust}、~L1 APG~\upcite{bao2012real}和增量视觉跟踪方法\upcite{ross2008incremental}等具有代表性的生成模型方法被提出。生成模型方法对于视角变化、目标被部分遮挡、目标尺度变化等情况有较好的处理效果，但是它无法充分利用目标的背景信息，因此在跟踪准确率的对比中判别模型方法更胜一筹。\par
    判别模型方法将目标跟踪抽象为一个二分类问题，分类器的训练数据来自图像中目标与背景的特征信息。训练完成的分类器将目标从背景中分离出来，实现目标的跟踪。\par
    基于相关滤波\upcite{bolme2010visual}的目标跟踪方法是判别模型方法中的一条分支，它将第一帧图像作为训练样本，训练学习一个滤波器，滤波器与下一帧中的各个搜索窗口进行相关运算，通过相关值确定下一帧中目标的最佳位置。最初相关滤波在目标跟踪中的应用先进性在于把整个跟踪问题建立在频域中，通过快速傅里叶变换加速相关值的计算，~MOSSE~\upcite{bolme2010visual}方法体现了这一先进性。面对大量的样本数据，稀疏采样策略会使样本之间存在很高的重叠率，产生的冗余数据限制了跟踪算法的性能，针对这一点，循环矩阵被应用于相关滤波之中，一个数据矩阵由数千个样本平移而成时，该矩阵呈现环状，如下所示：
    \begin{equation}
        \begin{bmatrix}
            x_1 & x_2 & x_3 & \cdots & x_n \\
            x_n & x_1 & x_2 & \cdots & x_{n-1} \\
            \vdots & \vdots & \vdots & \ddots & \vdots \\
            x_2 & x_3 & x_4 & \cdots & x_1
        \end{bmatrix}
        \label{cMatrix}
    \end{equation}
    循环矩阵具有良好的性质，能够通过傅里叶变换进行对角化从而减少计算量，~CSK~\upcite{henriques2012exploiting}充分利用了这一性质，将跟踪算法性能提升到数百帧的运行速度。之后基于相关滤波的目标跟踪方法又融合了多通道特征发展出核相关滤波（Kernelized Correlation Filters，KCF）\upcite{henriques2015high-speed}跟踪器和可分辨尺度空间跟踪器（Discriminative Scale Space Tracker，DSST）\upcite{danelljan2014accurate}。基于相关滤波器的目标跟踪方法在跟踪速度方面表现优异，通过在线学习保证了跟踪过程的实时性，如今已大规模地应用于工业中。\par
    基于深度学习的目标跟踪方法是判别模型方法中的另一条分支，它将目标区域标记为正样本，背景区域为负样本，经过学习之后的分类器在每一帧图像中区分正负样本，鉴别出目标区域，基于卷积神经网络的~UPDT~\upcite{bhat2018unveiling}方法是该领域的典型。在目标跟踪的应用中，深度学习更好地提取了目标的特征，通过低层特征对目标进行精准的定位，通过高层特征中的语义信息处理目标形变、跟踪漂移等情况。深度学习过度依赖于网络的训练以及速度，大量的标注训练数据的提供虽然能够使深度模型的训练更加容易，但是目标跟踪问题缺少大量训练数据，仅仅提供第一帧的~bounding box~，这使得模型的训练变得十分困难。~DLT~（Deep Learning Tracker）\upcite{wang2013learning}和~SO-DLT~\upcite{wang2015transferring}方法通过辅助图片数据预训练深度模型，并在在线跟踪时微调模型，克服了目标跟踪中训练数据缺失的难点。\par
\subsection{目标检测技术}
    目标检测作为计算机视觉领域一个重要的研究方向，其主要目的是在一张图像中寻找目标物体，确定这些物体的位置与大小，甚至通过模型的训练确定物体的类别，如图\ref{img2_6}所示。
    \begin{figure}[htb]
        \centering
        \includegraphics[width=0.9\textwidth]{2-6.png}
        \caption{目标检测实例}
        \label{img2_6}
    \end{figure}
    目标物体在图像中的表现具有随机性，无论是目标的位置、尺度还是形状，在图像中都是随机的，如何处理随机性成为目标检测中的核心问题。在视觉定位问题中借助目标检测技术获取图像中关键特征信息的位置，特征的位置信息能够辅助进行定位。然而目标检测同样面临着目标跟踪中的部分难点，目标物体的随机性、环境因素的干扰都对目标检测的准确度造成影响，这使得目标检测成为机器视觉领域最具有挑战性的问题。目标检测根据实现方式被分为传统方法与深度学习方法，近几年基于深度学习的目标检测方法研究较多，传统方法则逐渐变少。\par
    传统目标检测方法通常分为三部分，如图\ref{img2_4}所示，首先设置不同尺度、不同
    \begin{figure}[htb]
        \centering
        \includegraphics[width=0.9\textwidth]{2-4.pdf}
        \caption{传统目标检测方法的3个阶段}
        \label{img2_4}
    \end{figure}
    长宽比的窗口，利用滑动窗口策略对整幅图像进行遍历，通过大小不同的窗口截取图像的部分区域，然后在截取出来的图像区域中进行特征提取，进一步确定目标的相关特征，最后借助训练完毕的分类器对每一个区域中的物体进行分类。滑动窗口策略以一种穷举的思路进行区域选择，这使得目标检测的时间复杂度大幅上升，无法满足实时的要求。对目标区域的特征提取以手工特征的方式进行，比如方向梯度直方图（Histogram of Gradient，HOG）\upcite{dalal2005histograms}特征、SIFT\upcite{lowe2004distinctive}~特征、SURF~特征等，这种方式虽然使得传统目标检测方法在特定场景和较少类别的情况下取得比较好的效果，但是特征提取的稳定性却比较差。因此当光照等环境因素发生变化时，传统目标检测方法会出现大量的漏检与误检，效果呈现较差，而且检测速度也成为了传统目标检测方法的短板，深度学习的出现解决了这些问题。\par
    基于深度学习的目标检测方法借助深度学习对大脑认知的模拟行为实现对大量数据特征的分析处理，具有突出的目标检测能力，成为了当前目标检测的主流方向\upcite{zhou2017review}。基于深度学习的目标检测方法根据检测模型的不同分为以~R-CNN~\upcite{girshick2014rich}为代表的围绕~Region Proposal~展开的二阶段目标检测算法与以~YOLO~\upcite{redmon2016you}为代表的基于回归问题的一阶段目标检测算法。前者首先通过算法生成样本的候选框，然后使用卷积神经网络对样本进行分类，最后通过优化对检测框的位置进行休整，它在检测精度上占据优势，后者则不需要候选框的生成，而是将目标检测转化为回归问题，通过对目标物体进行回归获取目标的位置，它的检测精度虽然不及前者，但是由于放弃了候选框的生成，使得它的检测速度更快。
\section{位姿估计}
    在移动机器人定位问题中，位姿估计是最核心的部分，相机标定与目标检测均服务于位姿估计环节。对移动机器人进行定位的目的是求解移动机器人在空间中的位置与方向角，而位姿估计方法能够结合相机采集到图像中的视觉信息与相机本身的内外参，推算估计出目标的位姿，即位置与方向。\par
\subsection{常用位姿估计方法}
    在~VO~中，被用于对相机进行位姿估计的方法分为三种，它们分别是~2D-2D~方法、~3D-2D~方法、~3D-3D~方法。三种方法所需要的视觉信息各不相同，各自应用的场景也各不相同，但最终它们都能估计得到相机的位姿。\par
    ~2D-2D~方法指位姿估计所需的数据来源由多组对应的~2D~点组成，这个方法应用于相机存在位移与旋转，能够以多个角度对一个场景进行拍摄的情况。一对~2D~点的组合由一个~3D~点投影在两个不同位置的相机成像平面中产生，因此在理想状态下一组匹配点与各自光心的连线最终交汇于被投影的~3D~点，产生了对极几何约束，如图\ref{img2_7}所示，
    \begin{figure}[htb]
        \centering
        \includegraphics[width=0.7\textwidth]{2-7.pdf}
        \caption{对极几何约束}
        \label{img2_7}
    \end{figure}
    图中~$O_1$~、~$O_2$~、~$P$~三点共同确定了一个平面，该平面被称为极平面，~$O_1$~与~$O_2$~的连线被称为基线。假设第一帧时的相机位姿已知，那么第二帧的相机位姿可通过求解相机第一帧到第二帧的位姿转换进行估计，于是有如下公式表示对极约束：
    \begin{equation}
        p_2^{T}K^{-T}t^{\wedge}RK^{-1}p_1=0
        \label{epg}
    \end{equation}
    式中~$p_1$~与~$p_2$~表示两个匹配点的像素位置，~$K$~表示相机内参，~$R$~与~$t$~表示待求解的位姿转换关系。公式\ref{epg}是对对极约束的描述，~$O_1$~、~$O_2$~、~$P$~三点共面构成了对极约束的几何意义。为了进一步简化对极约束引入本质矩阵~$E$~，将本质矩阵表示为待求解的旋转矩阵~$R$~与平移向量~$t$~的外积，于是对相机位姿的估计问题被分解为求解本质矩阵以及根据本质矩阵求解~$R$~与~$t$~的两个子问题。~3*3~的本质矩共有~5~个自由度，考虑本质矩阵的非线性性质与尺度等价性，采用八点法\upcite{hartley1997in,longuethiggins1987a}对本质矩阵进行估计求解。本质矩阵本身由两个待求解的矩阵相乘所得，因此对本质矩阵采用奇异值分解，分解得到四组矩阵解，以~$P$~点在两个相机中都具有正深度为依据，剔除其他三组解，最终估计出第二帧相机的位姿。在得到两帧相机的位姿之后，通过三角测量方法求解~3D~点位置，由于噪声的存在，估计得到的位姿无法使~$O_1p_1$~与~$O_2p_2$~两条直线相交得到~$P$~，因此对于三角测量方法更多地采用最小二乘解而不是零解，最小二乘解指两条直线最接近时特征点的深度。~2D-2D~的对极几何约束方法通过构建极平面解决问题，但是它通常需要八个或八个以上的匹配点对，在特征缺失的场景下将无法使用，此外它还存在着初始化、纯旋转和尺度的问题。\par
    ~3D-3D~方法中不再出现相机模型，它所需的数据来源是多对匹配好的~3D~点，常用迭代最近点（Iterative Closest Point，ICP）\upcite{besl1992a}进行求解，~ICP~经常被用于激光~SLAM~以及~RGB-D SLAM~中。~ICP~的求解分为线性代数方法和非线性优化方法，前者首先计算两组点的质心位置，根据质心位置计算每个点的去质心坐标，然后采用最小二乘法求解使旋转后点的去质心坐标与匹配点去质心坐标误差最小的旋转矩阵，如公式\ref{ICP}所示：
    \begin{equation}
        arg \min_R \frac{1}{2} \sum_{i=1}^{n}||q_{1i}-Rq_{2i}||^2
        \label{ICP}
    \end{equation}
    式中~$q_{1i}$~与~$q_{2i}$~分别表示第~i~对点中第一个点与第二个点的去质心坐标，~$R$~表示待求解的旋转矩阵。最后通过求解得到的旋转矩阵计算平移量~$t$；后者则是以迭代的方式寻找最优值，同样构建最小二乘问题模型，用李代数\upcite{Gould1972Introduction}表示位姿，得到目标函数并通过不断地迭代找到极小值，在唯一解的情况下将这个极小值作为全局最优值。~3D-3D~方法的使用条件是已知特征点的深度，否则它无法进行位姿估计，也因为这一问题，使得~ICP~只能应用于容易获取深度的~RGB-D SLAM~以及激光~SLAM~中。\par
    ~3D-2D~方法也被称为~n~点透视（Perspective-n-Point，PnP）方法，它描述了已知多个~3D~点空间位置以及它们的投影点坐标时对相机所在位姿进行估计的过程。相比较约束较多的对极几何方法和应用面较窄的~ICP~，~PnP~方法可以在很少的匹配点中获得较好的运动估计，是比较实用的一种位姿估计方法。仅使用~3~对点进行位姿估计的~P3P~\upcite{gao2003complete}、直接线性变换\upcite{AbdelDirect}、高效~PnP~（Efficient PnP，EPnP）\upcite{lepetit2009epnp:}、未标定~PnP~（Uncalibrated PnP，UPnP）\upcite{penatesanchez2013exhaustive}都是常用的~PnP~方法，其中~EPnP~利用更多的点对信息，并用迭代的方式优化相机位姿以减少噪声的影响，同时能够快速进行位姿估计，因为这些优点~EPnP~被广泛采用。\par
\section{本章小结}
    本章描述了在计算机视觉领域中四大坐标系的转换关系，详细说明了相机标定、目标跟踪、目标检测、位姿估计这些辅助定位移动机器人的视觉方法，阐述了主流方法的优缺点并描述了它们在定位技术中的主要作用。